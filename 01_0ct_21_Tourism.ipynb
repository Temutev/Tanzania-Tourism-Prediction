{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-0ct-21  Tourism.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "93rJoJnRhh2X"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt \n",
        "% matplotlib inline \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57FbVNLQthiI"
      },
      "source": [
        "train =pd.read_csv('Train.csv')\n",
        "test = pd.read_csv('Test.csv')\n",
        "sub =pd.read_csv('SampleSubmission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MJQlBfttqYh"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e4dqDEPttQd"
      },
      "source": [
        "train.shape,test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTBZw4BNtzuc"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSuxaZqjiRxp"
      },
      "source": [
        "# missing data \n",
        "from feature_cleaning import missing_data as ms\n",
        "from data_exploration import explore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZj41-pLt1nn"
      },
      "source": [
        "# data exploration\n",
        "str_var_list, num_var_list, all_var_list = explore.get_dtypes(data=train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xxCto4uuGCV"
      },
      "source": [
        "print(str_var_list) # string type\n",
        "print(num_var_list) # numeric type\n",
        "print(all_var_list) # all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaQ-RyIJuMOJ"
      },
      "source": [
        "# General Data Description\n",
        "explore.describe(data=train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uARQM18duRbH"
      },
      "source": [
        "explore.continuous_var_distplot(x=train['total_cost'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgM1JNUKud3-"
      },
      "source": [
        "\n",
        "explore.correlation_plot(data=train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7df2cNeujdF"
      },
      "source": [
        "ms.check_missing(data=train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP3w8Z96uo0f"
      },
      "source": [
        "#filling in missing values \n",
        "\n",
        "train['travel_with'] = train['travel_with'].fillna(train['travel_with'].mode()[0])\n",
        "test['travel_with'] = test['travel_with'].fillna(test['travel_with'].mode()[0])\n",
        "\n",
        "train['total_female']=train['total_female'].fillna(train['total_female'].mode()[0])\n",
        "test['total_female']=test['total_female'].fillna(test['total_female'].mode()[0])\n",
        "\n",
        "train['total_male']=train['total_male'].fillna(train['total_male'].mode()[0])\n",
        "test['total_male']=test['total_male'].fillna(test['total_male'].mode()[0])\n",
        "\n",
        "train['most_impressing']=train['most_impressing'].fillna(train['most_impressing'].mode()[0])\n",
        "test['most_impressing']=test['most_impressing'].fillna(test['most_impressing'].mode()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrgOPecrwFkQ"
      },
      "source": [
        "ms.check_missing(data=train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IZZSEMzwIwi"
      },
      "source": [
        "ms.check_missing(data=test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jGQjqOawLo3"
      },
      "source": [
        "#Outliers\n",
        "from feature_cleaning import outlier as ot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niKBx5mLwPKY"
      },
      "source": [
        "index,para = ot.outlier_detect_IQR(data=train,col='total_cost',threshold=5)\n",
        "print('Upper bound:',para[0],'\\nLower bound:',para[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyH-2U_4wRdU"
      },
      "source": [
        "index,para = ot.outlier_detect_IQR(data=train,col='night_zanzibar',threshold=5)\n",
        "print('Upper bound:',para[0],'\\nLower bound:',para[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knj3gn0UwqvK"
      },
      "source": [
        "import category_encoders as ce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2m-jYjcwwuq"
      },
      "source": [
        "# Combine train and test set\n",
        "ntrain = train.shape[0] # to be used to split train and test set from the comb\n",
        "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
        "print(f'The shape of the combined dataframe is: {all_data.shape}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIBF5RAE9PD0"
      },
      "source": [
        "all_data['total_nights'] =all_data['night_zanzibar']+all_data['night_mainland']\n",
        "all_data['total_people'] = all_data['total_male'] + all_data['total_female']\n",
        "\n",
        "print(f'The shape of the combined dataframe is: {all_data.shape}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfFoOcbMwzLp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_data, all_data.total_cost, test_size=0.3,\n",
        "                                                    random_state=0)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qdOP4rbxAN1"
      },
      "source": [
        "ord_enc = ce.OrdinalEncoder(cols=['country', 'age_group', 'travel_with', 'purpose', \n",
        "                                  'main_activity', 'info_source', 'tour_arrangement', \n",
        "                                  'package_transport_int', 'package_accomodation', \n",
        "                                  'package_food', 'package_transport_tz', 'package_sightseeing', \n",
        "                                  'package_guided_tour', 'package_insurance', 'payment_mode',\n",
        "                                  'first_trip_tz', 'most_impressing']).fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DEElnijxXly"
      },
      "source": [
        "\n",
        "all_data = ord_enc.transform(all_data)\n",
        "all_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5Bp-wYtxZsl"
      },
      "source": [
        "main_cols = all_data.columns.difference(['ID', 'total_cost'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vhR65S_xlCy"
      },
      "source": [
        "# Separate train and test data from the combined dataframe\n",
        "train_df = all_data[:ntrain]\n",
        "test_df = all_data[ntrain:]\n",
        "\n",
        "# Check the shapes of the split dataset\n",
        "train_df.shape, test_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsgm5gt7x_dc"
      },
      "source": [
        "\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor,ExtraTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor,BaggingRegressor,AdaBoostRegressor,GradientBoostingRegressor,StackingRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# Regression\n",
        "from sklearn.linear_model import LinearRegression,Ridge,\\\n",
        "Lasso, Lars, LassoLars, ElasticNet, BayesianRidge, ARDRegression, SGDRegressor, PassiveAggressiveRegressor, HuberRegressor, RANSACRegressor,TheilSenRegressor\n",
        "\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.svm import SVR, NuSVR, LinearSVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
        "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor,\\\n",
        " ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
        "\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor, XGBRFRegressor\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjFo2huXy1b9"
      },
      "source": [
        "# Select main columns to be used in training\n",
        "\n",
        "X = train_df[main_cols]\n",
        "y = train_df.total_cost\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca6LUShmy-PN"
      },
      "source": [
        "logreg = LinearRegression()\n",
        "lgbmc = LGBMRegressor()\n",
        "xgbc =XGBRegressor()\n",
        "dtc =DecisionTreeRegressor()\n",
        "etc = ExtraTreeRegressor()\n",
        "rfc =RandomForestRegressor()\n",
        "abc =AdaBoostRegressor()\n",
        "gbc = GradientBoostingRegressor()\n",
        "cbc = CatBoostRegressor()\n",
        "sgd = SGDRegressor()\n",
        "br = BayesianRidge()\n",
        "\n",
        "ridge= Ridge()\n",
        "lasso= Lasso()\n",
        "lars = Lars()\n",
        "lassolars= LassoLars()\n",
        "elasticnet=  ElasticNet()\n",
        "ard =ARDRegression()\n",
        "passive= PassiveAggressiveRegressor()\n",
        "hbr =HuberRegressor() \n",
        "ransc=RANSACRegressor()\n",
        "theil =TheilSenRegressor()\n",
        "kr = KernelRidge()\n",
        "\n",
        "svrr=SVR()\n",
        "nsvrr= NuSVR()\n",
        "lsvr=LinearSVR()\n",
        "knn=KNeighborsRegressor()\n",
        "gpr =GaussianProcessRegressor()\n",
        "estimators =[\n",
        "             ('LInear Regression',logreg), ('LGBMRegressor',lgbmc), ('XGBRegressor',xgbc),('AdaBoostRegressor',abc),\n",
        "             ('DecisionTreeRegressor',dtc), ('ExtraTreesRegressor',etc),('RandomForestRegressor',rfc),\n",
        "             ('GradientBoostingRegressor',gbc), ('SGDRegressor',sgd), ('BayesianRidge',br),\n",
        "             ('ridge',ridge),('lasso',lasso),('lars',lars),('LassoLars',lassolars),\n",
        "             ('elasticnet',elasticnet),('ARD',ard),('Passive',passive),('HBR',hbr),\n",
        "             ('Ransca',ransc),('TheilSen',theil),('KernelRidge',kr),\n",
        "             ('SVR',svrr),('NuSVR',nsvrr),('KNN',knn),('LinearSVR',lsvr),\n",
        "             ('KNN',knn),('GPR',gpr),('cbc',cbc)\n",
        "]\n",
        "\n",
        "\n",
        "def model_training(X_train,X_test,y_train,y_test):\n",
        "    for e,r in estimators:\n",
        "        r.fit(X_train,y_train)\n",
        "        r_preds = r.predict(X_test)\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"F1 SCORE  for {} is >>>>    \".format(e),mae(y_test,r_preds))\n",
        "        \n",
        "        print(\"*****************************************************\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "        \n",
        "\n",
        "model_training(X_train,X_test,y_train,y_test)        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdOr-mkv_V2v"
      },
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVhQHxMxCfCC"
      },
      "source": [
        "test_df = test_df[main_cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4quQ2Jx_gbJ"
      },
      "source": [
        "folds = KFold(n_splits = 10)\n",
        "feature_importance_df = pd.DataFrame()\n",
        "\n",
        "predictions, predictions2 = [], []\n",
        "test_preds, test_preds = [], []\n",
        "y_preds, y_trues = [], []\n",
        "rmses, rmses2 = [], []\n",
        "\n",
        "for i,( train_index, test_index) in enumerate(folds.split(X, y)):\n",
        "    X_tra, X_val, y_tra, y_val = X.loc[train_index], X.loc[test_index], y[train_index], y[test_index]\n",
        "\n",
        "\n",
        "    lgbmc = LGBMRegressor()\n",
        "    rf = RandomForestRegressor(n_estimators=1000, random_state=5050)\n",
        "    lr = LinearRegression(normalize=True)\n",
        "    xgbr = XGBRegressor(objective = 'reg:squarederror')\n",
        "    hbr = HuberRegressor()\n",
        "\n",
        "    estimators_1 = [('xgbrregressor', xgbr), ('lgbmregressor', lgbmc)]\n",
        "    model = StackingRegressor(estimators=estimators_1, final_estimator=HuberRegressor() )\n",
        "    model2 = VotingRegressor(estimators=[('xgbrregressor', xgbr), ('lgbmregressor', lgbmc)], weights=[0.55, 0.45])\n",
        "\n",
        "    model.fit(X_tra, y_tra)\n",
        "    model2.fit(X_tra, y_tra)\n",
        "\n",
        "    preds = model.predict(test_df)\n",
        "    preds2 = model2.predict(test_df)\n",
        "    # test_pred = model.predict(X_test)\n",
        "    # test_preds.append(test_pred)\n",
        "    predictions.append(preds)\n",
        "    predictions2.append(preds2)\n",
        "    y_preds.extend(model.predict(X_val))\n",
        "    y_trues.extend(y_val)\n",
        "    rmse = mae(y_val, model.predict(X_val))\n",
        "    rmses.append(rmse)\n",
        "\n",
        "    rmse2 = mae(y_val, model2.predict(X_val))\n",
        "    rmses2.append(rmse2)\n",
        "    print(i, rmse, rmse2)\n",
        "\n",
        "    # fold_importance_df = pd.DataFrame({'feature': X.columns.tolist(), 'importance': model.feature_importances_})\n",
        "    # feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
        "    \n",
        "\n",
        "print(f'MAE:  {np.mean(rmses)}  {np.mean(rmse2)}  {(np.mean(rmses)+np.mean(rmse2))/2}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuHL_QoqB-NK"
      },
      "source": [
        " # Make predictions in test set and prepare submission file\n",
        "predzz = (np.mean(predictions, 0) *0.4 + np.mean(predictions2, 0)*0.6)\n",
        "sub_file = sub.copy()\n",
        "sub_file['total_cost'] = predzz\n",
        "sub_file.to_csv('lgbmr.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJFk4sBY0m--"
      },
      "source": [
        "# using catboost\n",
        "from catboost  import CatBoostRegressor,Pool\n",
        "\n",
        "train_dataset = Pool(X_train, y_train) \n",
        "test_dataset = Pool(X_test, y_test)\n",
        "\n",
        "cbr_oo = CatBoostRegressor(verbose=False)\n",
        "\n",
        "grid = {'iterations': [100, 150, 200],\n",
        "        'learning_rate': [0.03, 0.1],\n",
        "        'depth': [2, 4, 6, 8],\n",
        "        'l2_leaf_reg': [0.2, 0.5, 1, 3]}\n",
        "cbr_oo.grid_search(grid, train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc6cpgP1PzBs"
      },
      "source": [
        "pred =cbr_oo.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvmD1WvMQaLC"
      },
      "source": [
        "print(\"F1 SCORE  CBR is >>>>    \",mae(y_test,pred))\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deDJ2FdKVmUa"
      },
      "source": [
        "cbr_preds = cbr_oo.predict(test_df)\n",
        "\n",
        "sub_file['total_cost'] = cbr_preds\n",
        "sub_file.to_csv('fe_cbr.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XDVUnuLR3LS"
      },
      "source": [
        "# feature importance for three models \n",
        "sorted_feature_importance = cbr_oo.feature_importances_.argsort()\n",
        "plt.barh(X.columns, \n",
        "        cbr_oo.feature_importances_[sorted_feature_importance], \n",
        "        color='turquoise')\n",
        "plt.xlabel(\"CatBoost Feature Importance\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTtjDrFcaZZ9"
      },
      "source": [
        "sorted_feature_importance = xgbc.feature_importances_.argsort()\n",
        "plt.barh(X.columns, \n",
        "        xgbc.feature_importances_[sorted_feature_importance], \n",
        "        color='turquoise')\n",
        "plt.xlabel(\"XGBRegressor Feature Importance\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H09zWrvc59E"
      },
      "source": [
        "lightgbr =LGBMRegressor()\n",
        "lightgbr.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8xkSHQjb_f2"
      },
      "source": [
        "sorted_feature_importance = lightgbr.feature_importances_.argsort()\n",
        "plt.barh(X.columns, \n",
        "        lightgbr.feature_importances_[sorted_feature_importance], \n",
        "        color='turquoise')\n",
        "plt.xlabel(\"LightGBMRegressor Feature Importance\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBYY5kLA8TvT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}